{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../configs/user_config.yaml\") as f:\n",
    "    model_config = yaml.safe_load(f)\n",
    "\n",
    "load_dotenv(\"../configs/environment_variables.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge base Creation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defaults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_NAME = \"ch3_data\"\n",
    "DATA_PATH = \"../../data/ch3_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from azure.ai.generative.index import build_index\n",
    "from azure.ai.resources.client import AIClient\n",
    "from azure.ai.resources.operations._index_data_source import (\n",
    "    ACSOutputConfig,\n",
    "    LocalSource,\n",
    ")\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.aio import SearchClient\n",
    "from azure.search.documents.models import RawVectorQuery\n",
    "from openai import AsyncAzureOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cogsearch_index(\n",
    "    index_name: str,\n",
    "    path_to_data: str,\n",
    "    chunk_size: int,\n",
    "    chunk_overlap: int,\n",
    "    data_source_url: str = None,\n",
    "):\n",
    "    # Set up environment variables for cog search SDK\n",
    "    os.environ[\"AZURE_COGNITIVE_SEARCH_TARGET\"] = os.environ.get(\n",
    "        \"AZURE_AI_SEARCH_ENDPOINT\", \"\"\n",
    "    )\n",
    "    os.environ[\"AZURE_COGNITIVE_SEARCH_KEY\"] = os.environ.get(\"AZURE_AI_SEARCH_KEY\", \"\")\n",
    "\n",
    "    client = AIClient.from_config(DefaultAzureCredential())\n",
    "\n",
    "    default_aoai_connection = client.get_default_aoai_connection()\n",
    "    default_aoai_connection.set_current_environment()\n",
    "\n",
    "    default_acs_connection = client.connections.get(\n",
    "        os.environ.get(\"AZURE_COGNITIVE_SEARCH_CONNECTION_NAME\", \"\")\n",
    "    )\n",
    "    default_acs_connection.set_current_environment()\n",
    "\n",
    "    # Use the same index name when registering the index in AI Studio\n",
    "    index = build_index(\n",
    "        output_index_name=index_name,\n",
    "        vector_store=\"azure_cognitive_search\",\n",
    "        embeddings_model=f\"azure_open_ai://deployment/{os.environ.get('AZURE_OPENAI_EMBEDDING_DEPLOYMENT')}/model/{os.environ.get('AZURE_OPENAI_EMBEDDING_MODEL')}\",\n",
    "        data_source_url=data_source_url,\n",
    "        index_input_config=LocalSource(input_data=path_to_data),\n",
    "        acs_config=ACSOutputConfig(\n",
    "            acs_index_name=index_name,\n",
    "        ),\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "    )\n",
    "\n",
    "    # register the index so that it shows up in the project\n",
    "    cloud_index = client.indexes.create_or_update(index)\n",
    "\n",
    "    print(f\"Created index '{cloud_index.name}'\")\n",
    "    print(f\"Local Path: {index.path}\")\n",
    "    print(f\"Cloud Path: {cloud_index.path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest Documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AIClient: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "[DocumentChunksIterator::filter_extensions] Filtered 0 files out of 1\n",
      "[DocumentChunksIterator::crack_documents] Total time to load files: 4.839897155761719e-05\n",
      "{\n",
      "  \".txt\": 0.0,\n",
      "  \".md\": 0.0,\n",
      "  \".html\": 0.0,\n",
      "  \".htm\": 0.0,\n",
      "  \".py\": 0.0,\n",
      "  \".pdf\": 1.0,\n",
      "  \".ppt\": 0.0,\n",
      "  \".pptx\": 0.0,\n",
      "  \".doc\": 0.0,\n",
      "  \".docx\": 0.0,\n",
      "  \".xls\": 0.0,\n",
      "  \".xlsx\": 0.0\n",
      "}\n",
      "[DocumentChunksIterator::split_documents] Total time to split 62 documents into 161 chunks: 0.4794909954071045\n",
      "Processing document: CH3-data.pdf0\n",
      "Processing document: CH3-data.pdf1\n",
      "Processing document: CH3-data.pdf2\n",
      "Processing document: CH3-data.pdf3\n",
      "Processing document: CH3-data.pdf4\n",
      "Processing document: CH3-data.pdf5\n",
      "Processing document: CH3-data.pdf6\n",
      "Processing document: CH3-data.pdf7\n",
      "Processing document: CH3-data.pdf8\n",
      "Processing document: CH3-data.pdf9\n",
      "Processing document: CH3-data.pdf10\n",
      "Processing document: CH3-data.pdf11\n",
      "Processing document: CH3-data.pdf12\n",
      "Processing document: CH3-data.pdf13\n",
      "Processing document: CH3-data.pdf14\n",
      "Processing document: CH3-data.pdf15\n",
      "Processing document: CH3-data.pdf16\n",
      "Processing document: CH3-data.pdf17\n",
      "Processing document: CH3-data.pdf18\n",
      "Processing document: CH3-data.pdf19\n",
      "Processing document: CH3-data.pdf20\n",
      "Processing document: CH3-data.pdf21\n",
      "Processing document: CH3-data.pdf22\n",
      "Processing document: CH3-data.pdf23\n",
      "Processing document: CH3-data.pdf24\n",
      "Processing document: CH3-data.pdf25\n",
      "Processing document: CH3-data.pdf26\n",
      "Processing document: CH3-data.pdf27\n",
      "Processing document: CH3-data.pdf28\n",
      "Processing document: CH3-data.pdf29\n",
      "Processing document: CH3-data.pdf30\n",
      "Processing document: CH3-data.pdf31\n",
      "Processing document: CH3-data.pdf32\n",
      "Processing document: CH3-data.pdf33\n",
      "Processing document: CH3-data.pdf34\n",
      "Processing document: CH3-data.pdf35\n",
      "Processing document: CH3-data.pdf36\n",
      "Processing document: CH3-data.pdf37\n",
      "Processing document: CH3-data.pdf38\n",
      "Processing document: CH3-data.pdf39\n",
      "Processing document: CH3-data.pdf40\n",
      "Processing document: CH3-data.pdf41\n",
      "Processing document: CH3-data.pdf42\n",
      "Processing document: CH3-data.pdf43\n",
      "Processing document: CH3-data.pdf44\n",
      "Processing document: CH3-data.pdf45\n",
      "Processing document: CH3-data.pdf46\n",
      "Processing document: CH3-data.pdf47\n",
      "Processing document: CH3-data.pdf48\n",
      "Processing document: CH3-data.pdf49\n",
      "Processing document: CH3-data.pdf50\n",
      "Processing document: CH3-data.pdf51\n",
      "Processing document: CH3-data.pdf52\n",
      "Processing document: CH3-data.pdf53\n",
      "Processing document: CH3-data.pdf54\n",
      "Processing document: CH3-data.pdf55\n",
      "Processing document: CH3-data.pdf56\n",
      "Processing document: CH3-data.pdf57\n",
      "Processing document: CH3-data.pdf58\n",
      "Processing document: CH3-data.pdf59\n",
      "Processing document: CH3-data.pdf60\n",
      "Processing document: CH3-data.pdf61\n",
      "Processing document: CH3-data.pdf62\n",
      "Processing document: CH3-data.pdf63\n",
      "Processing document: CH3-data.pdf64\n",
      "Processing document: CH3-data.pdf65\n",
      "Processing document: CH3-data.pdf66\n",
      "Processing document: CH3-data.pdf67\n",
      "Processing document: CH3-data.pdf68\n",
      "Processing document: CH3-data.pdf69\n",
      "Processing document: CH3-data.pdf70\n",
      "Processing document: CH3-data.pdf71\n",
      "Processing document: CH3-data.pdf72\n",
      "Processing document: CH3-data.pdf73\n",
      "Processing document: CH3-data.pdf74\n",
      "Processing document: CH3-data.pdf75\n",
      "Processing document: CH3-data.pdf76\n",
      "Processing document: CH3-data.pdf77\n",
      "Processing document: CH3-data.pdf78\n",
      "Processing document: CH3-data.pdf79\n",
      "Processing document: CH3-data.pdf80\n",
      "Processing document: CH3-data.pdf81\n",
      "Processing document: CH3-data.pdf82\n",
      "Processing document: CH3-data.pdf83\n",
      "Processing document: CH3-data.pdf84\n",
      "Processing document: CH3-data.pdf85\n",
      "Processing document: CH3-data.pdf86\n",
      "Processing document: CH3-data.pdf87\n",
      "Processing document: CH3-data.pdf88\n",
      "Processing document: CH3-data.pdf89\n",
      "Processing document: CH3-data.pdf90\n",
      "Processing document: CH3-data.pdf91\n",
      "Processing document: CH3-data.pdf92\n",
      "Processing document: CH3-data.pdf93\n",
      "Processing document: CH3-data.pdf94\n",
      "Processing document: CH3-data.pdf95\n",
      "Processing document: CH3-data.pdf96\n",
      "Processing document: CH3-data.pdf97\n",
      "Processing document: CH3-data.pdf98\n",
      "Processing document: CH3-data.pdf99\n",
      "Processing document: CH3-data.pdf100\n",
      "Processing document: CH3-data.pdf101\n",
      "Processing document: CH3-data.pdf102\n",
      "Processing document: CH3-data.pdf103\n",
      "Processing document: CH3-data.pdf104\n",
      "Processing document: CH3-data.pdf105\n",
      "Processing document: CH3-data.pdf106\n",
      "Processing document: CH3-data.pdf107\n",
      "Processing document: CH3-data.pdf108\n",
      "Processing document: CH3-data.pdf109\n",
      "Processing document: CH3-data.pdf110\n",
      "Processing document: CH3-data.pdf111\n",
      "Processing document: CH3-data.pdf112\n",
      "Processing document: CH3-data.pdf113\n",
      "Processing document: CH3-data.pdf114\n",
      "Processing document: CH3-data.pdf115\n",
      "Processing document: CH3-data.pdf116\n",
      "Processing document: CH3-data.pdf117\n",
      "Processing document: CH3-data.pdf118\n",
      "Processing document: CH3-data.pdf119\n",
      "Processing document: CH3-data.pdf120\n",
      "Processing document: CH3-data.pdf121\n",
      "Processing document: CH3-data.pdf122\n",
      "Processing document: CH3-data.pdf123\n",
      "Processing document: CH3-data.pdf124\n",
      "Processing document: CH3-data.pdf125\n",
      "Processing document: CH3-data.pdf126\n",
      "Processing document: CH3-data.pdf127\n",
      "Processing document: CH3-data.pdf128\n",
      "Processing document: CH3-data.pdf129\n",
      "Processing document: CH3-data.pdf130\n",
      "Processing document: CH3-data.pdf131\n",
      "Processing document: CH3-data.pdf132\n",
      "Processing document: CH3-data.pdf133\n",
      "Processing document: CH3-data.pdf134\n",
      "Processing document: CH3-data.pdf135\n",
      "Processing document: CH3-data.pdf136\n",
      "Processing document: CH3-data.pdf137\n",
      "Processing document: CH3-data.pdf138\n",
      "Processing document: CH3-data.pdf139\n",
      "Processing document: CH3-data.pdf140\n",
      "Processing document: CH3-data.pdf141\n",
      "Processing document: CH3-data.pdf142\n",
      "Processing document: CH3-data.pdf143\n",
      "Processing document: CH3-data.pdf144\n",
      "Processing document: CH3-data.pdf145\n",
      "Processing document: CH3-data.pdf146\n",
      "Processing document: CH3-data.pdf147\n",
      "Processing document: CH3-data.pdf148\n",
      "Processing document: CH3-data.pdf149\n",
      "Processing document: CH3-data.pdf150\n",
      "Processing document: CH3-data.pdf151\n",
      "Processing document: CH3-data.pdf152\n",
      "Processing document: CH3-data.pdf153\n",
      "Processing document: CH3-data.pdf154\n",
      "Processing document: CH3-data.pdf155\n",
      "Processing document: CH3-data.pdf156\n",
      "Processing document: CH3-data.pdf157\n",
      "Processing document: CH3-data.pdf158\n",
      "Processing document: CH3-data.pdf159\n",
      "Processing document: CH3-data.pdf160\n",
      "Documents to embed: 161\n",
      "Documents reused: 0\n",
      "Attempt 0 to embed 16 documents.\n",
      "Attempt 0 to embed 16 documents.\n",
      "Attempt 0 to embed 16 documents.\n",
      "Attempt 0 to embed 16 documents.\n",
      "Attempt 0 to embed 16 documents.\n",
      "Attempt 0 to embed 16 documents.\n",
      "Attempt 0 to embed 16 documents.\n",
      "Attempt 0 to embed 16 documents.\n",
      "Attempt 0 to embed 16 documents.\n",
      "Attempt 0 to embed 16 documents.\n",
      "Attempt 0 to embed 1 documents.\n",
      "Updating ACS index\n",
      "Using Index fields: {\n",
      "  \"content\": \"content\",\n",
      "  \"url\": \"url\",\n",
      "  \"filename\": \"filepath\",\n",
      "  \"title\": \"title\",\n",
      "  \"metadata\": \"meta_json_string\",\n",
      "  \"embedding\": \"contentVector\"\n",
      "}\n",
      "Ensuring search index ch3_data exists\n",
      "Creating ch3_data search index\n",
      "Created ch3_data search index\n",
      "0 documents from sources marked for deletion, adding individual documents marked for deletion\n",
      "Total 0 documents marked for deletion\n",
      "Documents include embeddings: True\n",
      "Processing documents from: CH3-data\n",
      "Sending 100 documents to ACS\n",
      "Uploaded 100 documents to ACS in 5.9365 seconds, 0 failed\n",
      "Uploaded documents\n",
      "Sending 61 documents to ACS\n",
      "Uploaded 61 documents to ACS in 2.6714 seconds, 0 failed\n",
      "Uploaded documents\n",
      "Built index from 161 documents and 161 chunks, took 8.6223 seconds\n",
      "Built index\n",
      "Writing MLIndex yaml\n",
      "\u001b[32mUploading ch3_data-mlindex (0.0 MBs): 100%|██████████| 825/825 [00:00<00:00, 3247.40it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created index 'ch3_data'\n",
      "Local Path: /home/abin/Projects/openai-hackathon/hacks/codes/notebooks/ch3_data-mlindex\n",
      "Cloud Path: azureml://subscriptions/5f388ce8-ce4d-4fca-aff5-d39d62b5cb8e/resourcegroups/scb_openaihack_rg/workspaces/TestRunVinay/datastores/workspaceblobstore/paths/LocalUpload/1e5f08fb28a6c127d5203d90e06d1114/ch3_data-mlindex/\n"
     ]
    }
   ],
   "source": [
    "build_cogsearch_index(\n",
    "    index_name=INDEX_NAME,\n",
    "    path_to_data=DATA_PATH,\n",
    "    chunk_size=model_config[\"rag\"][\"chunk_size\"],\n",
    "    chunk_overlap=model_config[\"rag\"][\"chunk_overlap\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat with Documents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from typing import List\n",
    "\n",
    "import nest_asyncio\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_documents(\n",
    "    question: str,\n",
    "    index_name: str,\n",
    "    num_docs=5,\n",
    ") -> str:\n",
    "    #  retrieve documents relevant to the user's question from Cognitive Search\n",
    "    search_client = SearchClient(\n",
    "        endpoint=os.environ.get(\"AZURE_AI_SEARCH_ENDPOINT\", \"\"),\n",
    "        credential=AzureKeyCredential(os.environ.get(\"AZURE_AI_SEARCH_KEY\", \"\")),\n",
    "        index_name=index_name,\n",
    "    )\n",
    "\n",
    "    async with AsyncAzureOpenAI(\n",
    "        azure_endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\", \"\"),\n",
    "        api_key=os.environ.get(\"AZURE_OPENAI_KEY\", \"\"),\n",
    "        api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\", \"\"),\n",
    "    ) as aclient:\n",
    "\n",
    "        # generate a vector embedding of the user's question\n",
    "        embedding = await aclient.embeddings.create(\n",
    "            input=question, model=os.environ.get(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\")\n",
    "        )\n",
    "        embedding_to_query = embedding.data[0].embedding\n",
    "\n",
    "    context = \"\"\n",
    "    contexts = []\n",
    "    async with search_client:\n",
    "        # use the vector embedding to do a vector search on the index\n",
    "        vector_query = RawVectorQuery(\n",
    "            vector=embedding_to_query, k=num_docs, fields=\"contentVector\"\n",
    "        )\n",
    "        results = await search_client.search(\n",
    "            search_text=\"\", vector_queries=[vector_query], select=[\"id\", \"content\"]\n",
    "        )\n",
    "\n",
    "        async for result in results:\n",
    "            context += f\"\\n>>> {result['content']}\"\n",
    "            contexts.append(result[\"content\"])\n",
    "\n",
    "    return context, contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_message(user_prompt: str, system_role: str) -> List[dict]:\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ]\n",
    "\n",
    "\n",
    "def chat_completion(\n",
    "    question: str,\n",
    "    system_role: str,\n",
    "    user_prompt: str,\n",
    "    index_name: str,\n",
    "    num_docs: int = 5,\n",
    "    temperature: float = 0.7,\n",
    "    max_tokens: int = 800,\n",
    "):\n",
    "    # get search documents for the last user message in the conversation\n",
    "    context, contexts = asyncio.run(\n",
    "        get_documents(\n",
    "            question=question,\n",
    "            index_name=index_name,\n",
    "            num_docs=num_docs,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # TODO: Add context to user message\n",
    "    user_prompt = user_prompt.format(question=question, context=context)\n",
    "    message = build_message(user_prompt=user_prompt, system_role=system_role)\n",
    "\n",
    "    with AzureOpenAI(\n",
    "        azure_endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\", \"\"),\n",
    "        api_key=os.environ.get(\"AZURE_OPENAI_KEY\", \"\"),\n",
    "        api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\", \"\"),\n",
    "    ) as client:\n",
    "\n",
    "        # call Azure OpenAI with the system prompt and user's question\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            model=os.environ.get(\"AZURE_OPENAI_CHAT_DEPLOYMENT\"),\n",
    "            messages=message,\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens,\n",
    "        )\n",
    "\n",
    "    response = {\n",
    "        \"choices\": [\n",
    "            {\n",
    "                \"index\": 0,\n",
    "                \"message\": {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": chat_completion.choices[0].message.content,\n",
    "                },\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # add context in the returned response\n",
    "    context_dict = {\n",
    "        \"context\": context,\n",
    "        \"contexts\": contexts,\n",
    "        \"num_docs\": num_docs,\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": max_tokens,\n",
    "    }\n",
    "    response[\"choices\"][0][\"context\"] = context_dict\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_documents(question: str):\n",
    "    result = chat_completion(\n",
    "        question=question,\n",
    "        system_role=model_config[\"prompt\"][\"system_role\"],\n",
    "        user_prompt=model_config[\"prompt\"][\"user_prompt\"]\n",
    "        + \"\\n\\nQuestion:'{question}' \\n\\nContext: '{context}'\",\n",
    "        index_name=INDEX_NAME,\n",
    "        num_docs=model_config[\"rag\"][\"num_docs\"],\n",
    "        temperature=model_config[\"model\"][\"temperature\"],\n",
    "        max_tokens=model_config[\"model\"][\"max_tokens\"],\n",
    "    )\n",
    "    print(result[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question and Answering on the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If a Power Unit Manufacturer does not submit the Full Year Reporting Documentation by the deadline, the Cost Cap Administration will issue a late submission notice to the manufacturer. The manufacturer will then have 48 hours to provide a written explanation for the late submission. The Cost Cap Administration may grant an extension to the Full Year Reporting Deadline if it is satisfied with the written explanation. However, if the manufacturer does not provide a written response to the late submission notice within the specified time, provides an unsatisfactory response, or fails to submit the Full Year Reporting Documentation by the Extended Reporting Deadline, they will have committed a Non-Submission Breach. In such cases, they will be immediately referred to the Cost Cap Adjudication Panel, which may impose penalties such as a Constructors' Championship points deduction, a financial penalty, and/or other sporting penalties.\n"
     ]
    }
   ],
   "source": [
    "chat_with_documents(\n",
    "    question=\"Why did Formula 1 introduce limitations on the number of upgrades teams could make to their power units during the season?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureaistudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
